{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:04,193 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts\n",
      "2025-02-18 19:38:04,194 - apscheduler.scheduler - INFO - Added job \"SimpleCache.refresh_cache\" to job store \"default\"\n",
      "2025-02-18 19:38:04,195 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2025-02-18 19:38:04,195 - app.core.task.simple_cache - INFO - Started cache refresh scheduler to run every 24 hours.\n",
      "2025-02-18 19:38:04,195 - app.core.task.simple_cache - INFO - Starting cache refresh...\n",
      "2025-02-18 19:38:14,195 - apscheduler.executors.default - INFO - Running job \"SimpleCache.refresh_cache (trigger: interval[1 day, 0:00:00], next run at: 2025-02-18 19:38:14 +08)\" (scheduled at 2025-02-18 19:38:14.192442+08:00)\n",
      "2025-02-18 19:38:14,197 - app.core.task.simple_cache - INFO - Starting cache refresh...\n",
      "2025-02-18 19:38:23,368 - app.core.task.simple_cache - INFO - Cache refresh completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "from app.core.plan.evaluator import evaulate_answer\n",
    "from app.llm.interface import LLMInterface\n",
    "from app.config.settings import EVALUATION_LLM_PROVIDER, EVALUATION_LLM_MODEL\n",
    "\n",
    "from notebooks.plan_chat_optimizer import get_task_answer, update_plan, execute_task_using_new_plan\n",
    "from notebooks.tasks import get_evaluation_pending_tasks, record_evaluation\n",
    "\n",
    "eval_llm = LLMInterface(EVALUATION_LLM_PROVIDER, EVALUATION_LLM_MODEL)\n",
    "\n",
    "def optimize_plan(task_id:str, branch_name:Optional[str]=\"main\", max_iteration=3):\n",
    "    current_branch_name = branch_name\n",
    "    error_message = None\n",
    "    iteration_round = 0\n",
    "\n",
    "    while True:\n",
    "        iteration_round += 1\n",
    "        print(f\"Start to evaluate plan for task(id={task_id},branch={current_branch_name})\")\n",
    "        detail = get_task_answer(task_id, current_branch_name)\n",
    "\n",
    "        if detail is not None:\n",
    "            goal = detail.get(\"goal\")\n",
    "            final_answer = detail.get(\"final_answer\")\n",
    "            plan = detail.get(\"plan\")\n",
    "            metadata = detail.get(\"metadata\")\n",
    "\n",
    "            if plan is None:\n",
    "                record_evaluation(task_id, \"REJECTED\", \"No plan found\")\n",
    "                return\n",
    "\n",
    "            eval_res = evaulate_answer(eval_llm, goal, metadata, final_answer, plan)\n",
    "            eval_status = \"APPROVED\" if eval_res.get(\"accept\", False) else \"WAITING_FOR_EVALUATION\"\n",
    "            eval_reason = json.dumps(eval_res, indent=2) \n",
    "\n",
    "            record_evaluation(task_id, eval_status, eval_reason)\n",
    "\n",
    "            if eval_res.get(\"accept\", False) is True:\n",
    "                print(f\"Goal Pass! {goal}, evaluation result:{eval_reason}\")\n",
    "                return\n",
    "\n",
    "            print(f\"Goal Not Pass! {goal}, the evaluation result:{eval_reason}\")\n",
    "\n",
    "            if iteration_round >= max_iteration:\n",
    "                break\n",
    "\n",
    "            revised_plan = update_plan(goal, metadata, eval_reason, plan)\n",
    "            print(\"revised plan:\", revised_plan)\n",
    "            reasoning = revised_plan.get(\"reasoning\", None)\n",
    "            revised_plan = revised_plan.get(\"plan\", None)\n",
    "\n",
    "            try:\n",
    "                updated_result = execute_task_using_new_plan(task_id, revised_plan, reasoning)\n",
    "                print(f\"Revised plan execution result {updated_result}\")\n",
    "            except Exception as e:\n",
    "                error_message = f\"Failed to execute task using new plan {e}\"\n",
    "                break\n",
    "            \n",
    "            current_branch_name = updated_result.get(\"branch_name\", None)\n",
    "            current_final_answer = updated_result.get(\"final_answer\", None)\n",
    "            if current_branch_name is None or current_final_answer is None:\n",
    "                error_message = \"Failed to execut task using new plan, get empty answer\"\n",
    "                break\n",
    "    \n",
    "    if error_message is None:\n",
    "        error_message = \"Still failed after two evaluations round.\"\n",
    "    print(f\"Failed to evaluate plan for task(id={task_id}): {error_message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:28,360 - app.core.task.manager - INFO - Retrieved 18 tasks with evaluation statuses [<EvaluationStatus.NOT_EVALUATED: 'NOT_EVALUATED'>] between 2025-02-18 09:38:27.071674 and 2025-02-18 11:38:27.071725.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '2dc87c69-fd03-4c62-93d8-97a3a368e0d8',\n",
       "  'goal': 'What are the specific advantages and challenges of deploying the PD component in microservices mode in TiDB?',\n",
       "  'status': 'failed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 11, 5, 57),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 11, 6, 23),\n",
       "  'logs': 'Execution was interrupted by the client.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Complex Task Planning'},\n",
       "    {'label': 'Research & Analysis'},\n",
       "    {'label': 'Technical Design'}],\n",
       "   'response_format': {'Background': \"TiDB's PD component and its role in the architecture, including its functions such as metadata management, scheduling, and high availability. The microservices mode for PD was introduced experimentally in version 8.0.0 to reduce module interference and support larger workloads, as discussed in the previous conversation. Annotations: User is seeking detailed insights into the benefits and potential difficulties associated with deploying PD in microservices mode\",\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question does not involve SQL operations.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '55ac031c-68a6-429d-8976-a16ca9f3512b',\n",
       "  'goal': 'What is the command to scale out a TiDB cluster using TiUP?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 17, 28),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 18, 58),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Operation Guide'},\n",
       "    {'label': 'Basic Operations'}],\n",
       "   'response_format': {'Annotations': 'User is asking for the specific command to use TiUP for scaling out a TiDB cluster',\n",
       "    'Background': 'Instructions on using TiUP to scale out a TiDB cluster, including preparing a topology file, checking for potential risks, executing the scale-out command, and verifying the operation',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question pertains to TiUP commands rather than SQL operations.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '55bb0c88-2763-40b0-83b0-570a820496fe',\n",
       "  'goal': 'What are the best practices for performance optimization in TiDB?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 9, 53, 1),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 9, 53, 40),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Basic Knowledge'},\n",
       "    {'label': 'Guideline & Best Practice'}],\n",
       "   'response_format': {'Annotations': 'User is seeking guidance on optimizing TiDB performance, including best practices and strategies for improving efficiency and speed in TiDB environments',\n",
       "    'Background': 'TiDB performance tuning techniques and strategies',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'If (and only if) the answer contains SQL operations, please feel free to provide an example section at the end of the answer.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '59ed101b-fbcf-4bd3-aa95-c4e289f5c232',\n",
       "  'goal': 'If the `id` column is the primary key in the proposed SQL for partitioning a table in TiDB, how should the partition definition be structured?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 11, 12, 5),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 11, 13, 8),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Operation Guide'},\n",
       "    {'label': 'SQL Generation'}],\n",
       "   'response_format': {'Background': 'The user is asking about modifying the partition definition when the `id` column is a primary key in a table that uses hash partitioning based on the `status` column. The context involves understanding how primary keys interact with partition keys in TiDB, particularly regarding constraints and best practices for partitioned tables. Annotations: User needs guidance on defining partitions in a TiDB table where `id` is a primary key, and the table is partitioned by the `status` column using hash partitioning. Include SQLs Example Section: If (and only if) the answer contains SQL operations, please feel free to provide an example section at the end of the answer.',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'Japanese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '5fab14aa-83b1-4e67-951f-0dc3932427c1',\n",
       "  'goal': \"Are there any syntax issues with the following table definition in TiDB?\\n\\n```sql\\nCREATE TABLE `swap` (\\n    `id` BIGINT UNSIGNED AUTO_RANDOM NOT NULL,\\n    `network` VARCHAR(10) NOT NULL COMMENT '所属网络',\\n    `pool_address` VARCHAR(80) NOT NULL COMMENT '交易池地址',\\n    `block_number` BIGINT UNSIGNED NOT NULL COMMENT '区块号',\\n    `tx_hash` VARCHAR(100) NOT NULL COMMENT '交易哈希',\\n    `tx_index` INT UNSIGNED NOT NULL COMMENT '交易偏移量',\\n    `created` BIGINT UNSIGNED NOT NULL COMMENT '交易时间戳',\\n    `side_type` TINYINT UNSIGNED NOT NULL COMMENT '交易类型',\\n    `amount_in` VARCHAR(64) NOT NULL COMMENT '交易输入数量',\\n    `amount_out` VARCHAR(64) NOT NULL COMMENT '交易输出数量',\\n    `wallet` VARCHAR(80) NOT NULL COMMENT '支付钱包地址',\\n    `amount_in_token` VARCHAR(80) NOT NULL COMMENT '输入代币',\\n    `amount_out_token` VARCHAR(80) NOT NULL COMMENT '输出代币',\\n    `stable_usd_price` VARCHAR(64) NOT NULL COMMENT '稳定币美元价格',\\n    `token_usd_price` VARCHAR(64) NOT NULL COMMENT '兑换货币美元价格',\\n    `usd_volume` VARCHAR(64) NOT NULL COMMENT '交易总额(美元)',\\n    `version` VARCHAR(8) NOT NULL COMMENT '交易池版本',\\n    CLUSTERED INDEX `idx_pool_time` (`pool_address`, `created`),\\n    INDEX `idx_pool_address_wallet` (`pool_address`, `wallet`),\\n    INDEX `idx_block` (`block_number`)\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin TIDB_TABLE_OPTIONS='AUTO_RANDOM_BASE=1000000'\\nPARTITION BY RANGE (`created`) (\\n    PARTITION p202401 VALUES LESS THAN (UNIX_TIMESTAMP('2024-02-01')),\\n    PARTITION p202402 VALUES LESS THAN (UNIX_TIMESTAMP('2024-03-01')),\\n    PARTITION p202403 VALUES LESS THAN (UNIX_TIMESTAMP('2024-04-01')),\\n    PARTITION p202404 VALUES LESS THAN (UNIX_TIMESTAMP('2024-05-01')),\\n    PARTITION p202405 VALUES LESS THAN (UNIX_TIMESTAMP('2024-06-01')),\\n    PARTITION p202406 VALUES LESS THAN (UNIX_TIMESTAMP('2024-07-01')),\\n    PARTITION p202407 VALUES LESS THAN (UNIX_TIMESTAMP('2024-08-01')),\\n    PARTITION p202408 VALUES LESS THAN (UNIX_TIMESTAMP('2024-09-01')),\\n    PARTITION p202409 VALUES LESS THAN (UNIX_TIMESTAMP('2024-10-01')),\\n    PARTITION p202410 VALUES LESS THAN (UNIX_TIMESTAMP('2024-11-01')),\\n    PARTITION p202411 VALUES LESS THAN (UNIX_TIMESTAMP('2024-12-01')),\\n    PARTITION p202412 VALUES LESS THAN (UNIX_TIMESTAMP('2025-01-01')),\\n    PARTITION p202501 VALUES LESS THAN (UNIX_TIMESTAMP('2025-02-01')),\\n    PARTITION p202502 VALUES LESS THAN (UNIX_TIMESTAMP('2025-03-01')),\\n    PARTITION p202503 VALUES LESS THAN (UNIX_TIMESTAMP('2025-04-01')),\\n    PARTITION p202504 VALUES LESS THAN (UNIX_TIMESTAMP('2025-05-01')),\\n    PARTITION p202505 VALUES LESS THAN (UNIX_TIMESTAMP('2025-06-01')),\\n    PARTITION p202506 VALUES LESS THAN (UNIX_TIMESTAMP('2025-07-01')),\\n    PARTITION p202507 VALUES LESS THAN (UNIX_TIMESTAMP('2025-08-01')),\\n    PARTITION p202508 VALUES LESS THAN (UNIX_TIMESTAMP('2025-09-01')),\\n    PARTITION p202509 VALUES LESS THAN (UNIX_TIMESTAMP('2025-10-01')),\\n    PARTITION p202510 VALUES LESS THAN (UNIX_TIMESTAMP('2025-11-01')),\\n    PARTITION p202511 VALUES LESS THAN (UNIX_TIMESTAMP('2025-12-01')),\\n    PARTITION p202512 VALUES LESS THAN (UNIX_TIMESTAMP('2026-01-01')),\\n    PARTITION p202601 VALUES LESS THAN (UNIX_TIMESTAMP('2026-02-01')),\\n    PARTITION p202602 VALUES LESS THAN (UNIX_TIMESTAMP('2026-03-01')),\\n    PARTITION p202603 VALUES LESS THAN (UNIX_TIMESTAMP('2026-04-01')),\\n    PARTITION p202604 VALUES LESS THAN (UNIX_TIMESTAMP('2026-05-01')),\\n    PARTITION p202605 VALUES LESS THAN (UNIX_TIMESTAMP('2026-06-01')),\\n    PARTITION p202606 VALUES LESS THAN (UNIX_TIMESTAMP('2026-07-01')),\\n    PARTITION p202607 VALUES LESS THAN (UNIX_TIMESTAMP('2026-08-01')),\\n    PARTITION p202608 VALUES LESS THAN (UNIX_TIMESTAMP('2026-09-01')),\\n    PARTITION p202609 VALUES LESS THAN (UNIX_TIMESTAMP('2026-10-01')),\\n    PARTITION p202610 VALUES LESS THAN (UNIX_TIMESTAMP('2026-11-01')),\\n    PARTITION p202611 VALUES LESS THAN (UNIX_TIMESTAMP('2026-12-01')),\\n    PARTITION p202612 VALUES LESS THAN (UNIX_TIMESTAMP('2027-01-01')),\\n    PARTITION pfuture VALUES LESS THAN MAXVALUE\\n);\\n```\",\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 45, 19),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 46, 42),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Troubleshooting'},\n",
       "    {'label': 'SQL Syntax Error'}],\n",
       "   'response_format': {'Annotations': 'User is asking for syntax validation of a table definition in TiDB, focusing on potential issues with the use of `AUTO_RANDOM`, partitioning, and index definitions',\n",
       "    'Background': 'TiDB table creation syntax, partitioning, and index management',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question is about syntax validation.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '6af4a274-983d-4817-adc8-13e4fad9ffec',\n",
       "  'goal': 'What is MySQL?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 9, 50, 49),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 9, 51, 8),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Other Topics'}],\n",
       "   'response_format': {'Annotations': 'User is asking for information about MySQL, and it is important to provide a comparison with TiDB to highlight similarities and differences',\n",
       "    'Background': 'General introduction to MySQL, with a focus on comparing its features to TiDB where applicable',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '6cf09abd-8910-45e2-9842-524214490ca4',\n",
       "  'goal': 'tiup mirror merge 命令的作用是什么？',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 9, 50, 27),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 9, 50, 55),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Basic Knowledge'},\n",
       "    {'label': 'Feature Support'}],\n",
       "   'response_format': {'Background': 'TiUP 是 TiDB 的包管理工具，用于管理 TiDB 集群的各个组件和版本，tiup mirror merge 是 TiUP 的一个命令，用于合并多个镜像仓库，通常用于在离线环境中更新或管理 TiDB 组件版本。Annotations: 用户希望了解 tiup mirror merge 命令的具体功能和使用场景',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '81a9e7e9-f18a-44cd-8ac2-ebfd4781e02d',\n",
       "  'goal': 'NUMA binding failure in TiDB',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 10, 17),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 11, 44),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Troubleshooting'},\n",
       "    {'label': 'Common Issues'}],\n",
       "   'response_format': {'Annotations': 'User is experiencing an issue related to NUMA binding in TiDB. The response should address potential causes and solutions for NUMA-related problems in a TiDB environment, considering performance optimization and troubleshooting steps.',\n",
       "    'Background': 'NUMA (Non-Uniform Memory Access) configuration and its impact on TiDB performance',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '871b70e7-c036-498c-8a9b-ea6dc4b9c65b',\n",
       "  'goal': 'What are the specifications for scaling out using TiUP?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 14, 23),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 16, 38),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Operation Guide'},\n",
       "    {'label': 'Basic Operations'}],\n",
       "   'response_format': {'Background': 'TiUP is a cluster management tool for TiDB, and scaling out involves adding new nodes or components to an existing TiDB cluster. The user is asking for guidance on how to perform this operation using TiUP, which typically involves specifying the topology of the new nodes and executing the appropriate TiUP commands. Annotations: User needs detailed instructions on using TiUP to scale out a TiDB cluster, including any necessary commands and configuration details',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question pertains to TiUP operations rather than SQL operations.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': '949c9928-8c07-45df-8edb-3773319c4be0',\n",
       "  'goal': 'Compare TiDB and Citus in detail, and provide guidance on how to choose between them for a project.',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 9, 59, 48),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 2, 24),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Complex Task Planning'},\n",
       "    {'label': 'Research & Analysis'},\n",
       "    {'label': 'Comparative Analysis'}],\n",
       "   'response_format': {'Annotations': 'User is seeking a detailed comparison between TiDB and Citus, focusing on their features, performance, scalability, and suitability for different types of projects. The response should help the user make an informed decision on which database system to choose for their specific project needs.',\n",
       "    'Background': 'Overview of TiDB and Citus features, strengths, and use cases',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'a301ba2a-1639-456b-8c89-8d5942436ac4',\n",
       "  'goal': 'How to generate the DDL statements for all tables in TiDB?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 11, 4, 40),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 11, 5, 6),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Operation Guide'},\n",
       "    {'label': 'SQL Generation'}],\n",
       "   'response_format': {'Annotations': 'User is asking for a method to extract the DDL statements for all tables within a TiDB database',\n",
       "    'Background': 'TiDB schema management and DDL generation',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'If (and only if) the answer contains SQL operations, please feel free to provide an example section at the end of the answer.',\n",
       "    'Lang': 'Japanese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'b0481b98-92c6-4fd1-944a-8a9d383d86a6',\n",
       "  'goal': 'How to address the error related to assertion failure in TiDB, specifically the \"assertion failure\" in prewrite.rs, and what steps can be taken to resolve it?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 55, 28),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 55, 58),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Troubleshooting'},\n",
       "    {'label': 'Common Issues'}],\n",
       "   'response_format': {'Annotations': 'The user is experiencing an assertion failure during the prewrite phase, indicating a potential data inconsistency issue. The response should guide the user on how to troubleshoot and resolve this specific error',\n",
       "    'Background': \"The user previously encountered a similar error related to data inconsistency between data and indexes in TiDB, which can occur during transaction execution. The assistant provided potential causes and solutions, including contacting TiDB support, disabling certain checks, and rewriting SQL statements. The current error message suggests a similar issue during the prewrite phase of a transaction, which is part of TiDB's transaction processing mechanism\",\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the focus is on error resolution rather than SQL operations.',\n",
       "    'Lang': 'English'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'b3b537af-ef4b-4fc9-a612-fcc448aa5f57',\n",
       "  'goal': 'What is the ticdc_kvclient_cached_region metric in TiDB?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 9, 59, 10),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 9, 59, 53),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Basic Knowledge'},\n",
       "    {'label': 'Feature Support'},\n",
       "    {'label': 'TiCDC'}],\n",
       "   'response_format': {'Annotations': \"User is asking for an explanation of the specific TiCDC metric <ticdc_kvclient_cached_region>, which is related to TiCDC's internal operations and performance monitoring in TiDB.\",\n",
       "    'Background': 'TiCDC metrics and monitoring in TiDB',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'English'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'c255c42b-c85d-450f-aa2b-b101f37adef8',\n",
       "  'goal': 'Who are you?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 24, 57),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 25, 8),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Other Topics'},\n",
       "    {'label': 'Unclear Context'}],\n",
       "   'response_format': {'Annotations': 'The user is asking about the identity and capabilities of the TiDB Docs Bot, which specializes in providing information and assistance related to the TiDB database.',\n",
       "    'Background': 'Introduction to TiDB Docs Bot capabilities',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'English'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'c5c0bc70-8b3f-437e-9c4b-4563e4c79be4',\n",
       "  'goal': 'When does disk space get reclaimed for row deletions in TiDB?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 10, 42),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 11, 11),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Basic Knowledge'},\n",
       "    {'label': 'Feature Support'}],\n",
       "   'response_format': {'Annotations': \"User is asking about the process and timing of disk space reclamation after row deletions in TiDB, which involves understanding TiDB's garbage collection mechanism and how it manages storage space\",\n",
       "    'Background': \"TiDB's storage engine and garbage collection process\",\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question is about storage management rather than SQL operations.',\n",
       "    'Lang': 'English'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'cf211e26-2517-4264-8354-d2989f594093',\n",
       "  'goal': 'What is the maximum number of nodes that a TiDB cluster can have in a real-world scenario?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 9, 58, 42),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 9, 59, 33),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Basic Knowledge'},\n",
       "    {'label': 'Feature Support'}],\n",
       "   'response_format': {'Annotations': 'User is inquiring about the scalability limits of a TiDB cluster in terms of the number of nodes, including TiDB, TiKV, and PD nodes',\n",
       "    'Background': 'TiDB cluster architecture and scalability',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question pertains to cluster architecture rather than SQL operations.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'd86ef57b-946a-4d69-b3b1-d9e04beb0bd2',\n",
       "  'goal': \"How to evaluate the impact of future expansion plans on the choice between TiDB and Citus? What specific measures do TiDB and Citus have for handling data security and privacy? How is Citus's sharding capability specifically implemented in multi-tenant application scenarios? What are some successful cases of TiDB's HTAP capabilities in practical applications? In scenarios involving geographically distributed data, how does Citus ensure data consistency and access speed?\",\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 10, 3, 58),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 10, 6, 41),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Complex Task Planning'},\n",
       "    {'label': 'Research & Analysis'},\n",
       "    {'label': 'Comparative Analysis'}],\n",
       "   'response_format': {'Annotations': 'User is seeking detailed insights into the scalability, security, and specific technical implementations of TiDB and Citus, including real-world examples and technical explanations',\n",
       "    'Background': 'Comparison of TiDB and Citus features, focusing on scalability, data security, privacy, multi-tenancy, HTAP capabilities, and geographic distribution',\n",
       "    'Format': 'text',\n",
       "    'Include SQLs Example Section': 'Not applicable as the question does not involve specific SQL operations.',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'},\n",
       " {'id': 'efbdb0ed-835b-4584-b0ff-5b1cc075ef4b',\n",
       "  'goal': 'Why do we need the PD (Placement Driver) microservice in TiDB, and in what scenarios or data volume should it be enabled?',\n",
       "  'status': 'completed',\n",
       "  'created_at': datetime.datetime(2025, 2, 18, 11, 4, 22),\n",
       "  'updated_at': datetime.datetime(2025, 2, 18, 11, 5, 38),\n",
       "  'logs': 'Plan execution completed.',\n",
       "  'best_plan': None,\n",
       "  'metadata': {'label_path': [{'label': 'Complex Task Planning'},\n",
       "    {'label': 'Research & Analysis'},\n",
       "    {'label': 'Product Overview'}],\n",
       "   'response_format': {'Annotations': 'User is asking about the necessity and application scenarios of the PD component in TiDB, particularly focusing on when it becomes essential based on data volume or specific use cases.',\n",
       "    'Background': 'Explanation of the role of the PD component in TiDB architecture, including its responsibilities in managing metadata, scheduling, and load balancing. Discuss scenarios where PD is crucial, such as large-scale deployments and high availability requirements',\n",
       "    'Format': 'text',\n",
       "    'Lang': 'Chinese'}},\n",
       "  'evaluation_status': 'NOT_EVALUATED',\n",
       "  'human_evaluation_status': 'NOT_EVALUATED'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(hours=2)\n",
    "\n",
    "pending_tasks = get_evaluation_pending_tasks(\n",
    "    start_time=start_time\n",
    ")\n",
    "pending_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to evaluate plan for task(id=2dc87c69-fd03-4c62-93d8-97a3a368e0d8,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:33,560 - app.core.task.simple_cache - INFO - Cache refresh completed successfully.\n",
      "2025-02-18 19:38:33,561 - apscheduler.executors.default - INFO - Job \"SimpleCache.refresh_cache (trigger: interval[1 day, 0:00:00], next run at: 2025-02-19 19:38:14 +08)\" executed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:35,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Not Pass! What are the specific advantages and challenges of deploying the PD component in microservices mode in TiDB?, the evaluation result:{\n",
      "  \"accept\": false,\n",
      "  \"plan_adjustment_suggestion\": \"The Plan lacks dual retrieval, which could enhance the quality of the information gathered. It should incorporate both retrieve_knowledge_graph and vector_search tools to ensure comprehensive data collection. Additionally, the Plan should include immediate processing of combined results through the LLM generation tool to extract key insights and present a coherent narrative. The absence of a Final Answer suggests a possible execution error or incomplete data processing, which needs to be addressed.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Failed to evaluate plan for task(id=2dc87c69-fd03-4c62-93d8-97a3a368e0d8): Still failed after two evaluations round.\n",
      "Start to evaluate plan for task(id=55ac031c-68a6-429d-8976-a16ca9f3512b,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:40,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! What is the command to scale out a TiDB cluster using TiUP?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"While the answer is acceptable and provides a comprehensive guide on scaling out a TiDB cluster using TiUP, the Plan could be improved by ensuring that the retrieval steps are more focused on directly addressing the user's primary query about the specific command. The Plan currently includes extensive information on topology preparation, risks, and verification, which, while useful, may not be necessary for a user solely interested in the command itself. Streamlining the Plan to prioritize the retrieval and generation of the specific command could enhance efficiency.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=55bb0c88-2763-40b0-83b0-570a820496fe,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:44,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! What are the best practices for performance optimization in TiDB?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively addresses the Goal by providing a comprehensive overview of best practices for performance optimization in TiDB. However, the Plan could be improved by ensuring dual retrieval is consistently followed by immediate processing through the LLM generation tool to extract key insights and present a coherent narrative. Additionally, the Plan should ensure that the retrieval results are not passed as raw data to non-LLM tools, which could lead to inefficiencies.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=59ed101b-fbcf-4bd3-aa95-c4e289f5c232,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:51,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! If the `id` column is the primary key in the proposed SQL for partitioning a table in TiDB, how should the partition definition be structured?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Plan successfully retrieves relevant information and generates an appropriate SQL example in Japanese. However, it could be improved by implementing dual retrieval using both retrieve_knowledge_graph and vector_search tools to ensure comprehensive coverage of TiDB partitioning features and primary key constraints. Additionally, the Plan should immediately process combined results through the LLM generation tool to extract key insights and present a coherent narrative. This would enhance the robustness and reliability of the Final Answer.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=5fab14aa-83b1-4e67-951f-0dc3932427c1,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:38:56,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Not Pass! Are there any syntax issues with the following table definition in TiDB?\n",
      "\n",
      "```sql\n",
      "CREATE TABLE `swap` (\n",
      "    `id` BIGINT UNSIGNED AUTO_RANDOM NOT NULL,\n",
      "    `network` VARCHAR(10) NOT NULL COMMENT '所属网络',\n",
      "    `pool_address` VARCHAR(80) NOT NULL COMMENT '交易池地址',\n",
      "    `block_number` BIGINT UNSIGNED NOT NULL COMMENT '区块号',\n",
      "    `tx_hash` VARCHAR(100) NOT NULL COMMENT '交易哈希',\n",
      "    `tx_index` INT UNSIGNED NOT NULL COMMENT '交易偏移量',\n",
      "    `created` BIGINT UNSIGNED NOT NULL COMMENT '交易时间戳',\n",
      "    `side_type` TINYINT UNSIGNED NOT NULL COMMENT '交易类型',\n",
      "    `amount_in` VARCHAR(64) NOT NULL COMMENT '交易输入数量',\n",
      "    `amount_out` VARCHAR(64) NOT NULL COMMENT '交易输出数量',\n",
      "    `wallet` VARCHAR(80) NOT NULL COMMENT '支付钱包地址',\n",
      "    `amount_in_token` VARCHAR(80) NOT NULL COMMENT '输入代币',\n",
      "    `amount_out_token` VARCHAR(80) NOT NULL COMMENT '输出代币',\n",
      "    `stable_usd_price` VARCHAR(64) NOT NULL COMMENT '稳定币美元价格',\n",
      "    `token_usd_price` VARCHAR(64) NOT NULL COMMENT '兑换货币美元价格',\n",
      "    `usd_volume` VARCHAR(64) NOT NULL COMMENT '交易总额(美元)',\n",
      "    `version` VARCHAR(8) NOT NULL COMMENT '交易池版本',\n",
      "    CLUSTERED INDEX `idx_pool_time` (`pool_address`, `created`),\n",
      "    INDEX `idx_pool_address_wallet` (`pool_address`, `wallet`),\n",
      "    INDEX `idx_block` (`block_number`)\n",
      ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin TIDB_TABLE_OPTIONS='AUTO_RANDOM_BASE=1000000'\n",
      "PARTITION BY RANGE (`created`) (\n",
      "    PARTITION p202401 VALUES LESS THAN (UNIX_TIMESTAMP('2024-02-01')),\n",
      "    PARTITION p202402 VALUES LESS THAN (UNIX_TIMESTAMP('2024-03-01')),\n",
      "    PARTITION p202403 VALUES LESS THAN (UNIX_TIMESTAMP('2024-04-01')),\n",
      "    PARTITION p202404 VALUES LESS THAN (UNIX_TIMESTAMP('2024-05-01')),\n",
      "    PARTITION p202405 VALUES LESS THAN (UNIX_TIMESTAMP('2024-06-01')),\n",
      "    PARTITION p202406 VALUES LESS THAN (UNIX_TIMESTAMP('2024-07-01')),\n",
      "    PARTITION p202407 VALUES LESS THAN (UNIX_TIMESTAMP('2024-08-01')),\n",
      "    PARTITION p202408 VALUES LESS THAN (UNIX_TIMESTAMP('2024-09-01')),\n",
      "    PARTITION p202409 VALUES LESS THAN (UNIX_TIMESTAMP('2024-10-01')),\n",
      "    PARTITION p202410 VALUES LESS THAN (UNIX_TIMESTAMP('2024-11-01')),\n",
      "    PARTITION p202411 VALUES LESS THAN (UNIX_TIMESTAMP('2024-12-01')),\n",
      "    PARTITION p202412 VALUES LESS THAN (UNIX_TIMESTAMP('2025-01-01')),\n",
      "    PARTITION p202501 VALUES LESS THAN (UNIX_TIMESTAMP('2025-02-01')),\n",
      "    PARTITION p202502 VALUES LESS THAN (UNIX_TIMESTAMP('2025-03-01')),\n",
      "    PARTITION p202503 VALUES LESS THAN (UNIX_TIMESTAMP('2025-04-01')),\n",
      "    PARTITION p202504 VALUES LESS THAN (UNIX_TIMESTAMP('2025-05-01')),\n",
      "    PARTITION p202505 VALUES LESS THAN (UNIX_TIMESTAMP('2025-06-01')),\n",
      "    PARTITION p202506 VALUES LESS THAN (UNIX_TIMESTAMP('2025-07-01')),\n",
      "    PARTITION p202507 VALUES LESS THAN (UNIX_TIMESTAMP('2025-08-01')),\n",
      "    PARTITION p202508 VALUES LESS THAN (UNIX_TIMESTAMP('2025-09-01')),\n",
      "    PARTITION p202509 VALUES LESS THAN (UNIX_TIMESTAMP('2025-10-01')),\n",
      "    PARTITION p202510 VALUES LESS THAN (UNIX_TIMESTAMP('2025-11-01')),\n",
      "    PARTITION p202511 VALUES LESS THAN (UNIX_TIMESTAMP('2025-12-01')),\n",
      "    PARTITION p202512 VALUES LESS THAN (UNIX_TIMESTAMP('2026-01-01')),\n",
      "    PARTITION p202601 VALUES LESS THAN (UNIX_TIMESTAMP('2026-02-01')),\n",
      "    PARTITION p202602 VALUES LESS THAN (UNIX_TIMESTAMP('2026-03-01')),\n",
      "    PARTITION p202603 VALUES LESS THAN (UNIX_TIMESTAMP('2026-04-01')),\n",
      "    PARTITION p202604 VALUES LESS THAN (UNIX_TIMESTAMP('2026-05-01')),\n",
      "    PARTITION p202605 VALUES LESS THAN (UNIX_TIMESTAMP('2026-06-01')),\n",
      "    PARTITION p202606 VALUES LESS THAN (UNIX_TIMESTAMP('2026-07-01')),\n",
      "    PARTITION p202607 VALUES LESS THAN (UNIX_TIMESTAMP('2026-08-01')),\n",
      "    PARTITION p202608 VALUES LESS THAN (UNIX_TIMESTAMP('2026-09-01')),\n",
      "    PARTITION p202609 VALUES LESS THAN (UNIX_TIMESTAMP('2026-10-01')),\n",
      "    PARTITION p202610 VALUES LESS THAN (UNIX_TIMESTAMP('2026-11-01')),\n",
      "    PARTITION p202611 VALUES LESS THAN (UNIX_TIMESTAMP('2026-12-01')),\n",
      "    PARTITION p202612 VALUES LESS THAN (UNIX_TIMESTAMP('2027-01-01')),\n",
      "    PARTITION pfuture VALUES LESS THAN MAXVALUE\n",
      ");\n",
      "```, the evaluation result:{\n",
      "  \"accept\": false,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer does not directly address the specific syntax issues in the provided table definition. It provides general advice on TiDB features like AUTO_RANDOM and partitioning but does not identify specific syntax errors or confirm the correctness of the SQL statement. The Plan should include a step to directly analyze the provided SQL statement against TiDB's syntax rules, possibly using a tool to validate the SQL syntax directly. Additionally, the Plan should ensure that the answer explicitly confirms whether the given SQL statement is correct or highlights specific syntax errors.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Failed to evaluate plan for task(id=5fab14aa-83b1-4e67-951f-0dc3932427c1): Still failed after two evaluations round.\n",
      "Start to evaluate plan for task(id=6af4a274-983d-4817-adc8-13e4fad9ffec,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:02,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! What is MySQL?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Plan effectively generates a comprehensive answer by using two LLM generation steps: one for introducing MySQL and another for comparing MySQL with TiDB. However, the Plan could be improved by incorporating a dual retrieval step to ensure that the information is up-to-date and accurate, especially when discussing technical aspects and comparisons. This would involve using both retrieve_knowledge_graph and vector_search tools to gather the latest data before generating the final answer.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=6cf09abd-8910-45e2-9842-524214490ca4,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:08,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! tiup mirror merge 命令的作用是什么？, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"While the answer is acceptable, the Plan could be improved by ensuring that the retrieval steps are more focused on extracting the most relevant and concise information. The Plan should also ensure that the dual retrieval process is immediately followed by processing through the LLM generation tool to avoid any potential inclusion of irrelevant data. Additionally, the Plan could benefit from explicitly checking for any missing steps that might overlook critical aspects of the Goal.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=81a9e7e9-f18a-44cd-8ac2-ebfd4781e02d,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:13,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! NUMA binding failure in TiDB, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively addresses the user's Goal by providing a comprehensive analysis of potential causes and solutions for NUMA binding failures in TiDB. However, the Plan could be improved by ensuring that each retrieval step is immediately followed by processing through the LLM generation tool to extract key insights and present a coherent narrative. This would enhance the efficiency of the Plan and ensure that the information is synthesized effectively at each stage.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=871b70e7-c036-498c-8a9b-ea6dc4b9c65b,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:18,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! What are the specifications for scaling out using TiUP?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively resolves the user's Goal by providing a comprehensive and detailed guide on how to scale out a TiDB cluster using TiUP. However, the Plan could be improved by ensuring that each retrieval step is immediately followed by processing through the LLM generation tool to extract key insights and present a coherent narrative. This would prevent any potential loss of context or information between retrieval and generation steps. Additionally, the Plan should ensure that all retrievals are necessary and directly contribute to the Final Answer, avoiding any redundant steps.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=949c9928-8c07-45df-8edb-3773319c4be0,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:23,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! Compare TiDB and Citus in detail, and provide guidance on how to choose between them for a project., evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively resolves the Goal by providing a detailed comparison of TiDB and Citus, focusing on their features, performance, scalability, and use cases. However, the Plan could be improved by ensuring that after each dual retrieval (using both vector_search and retrieve_knowledge_graph), the results are immediately processed through the LLM generation tool to extract key insights and present a coherent narrative. This would prevent the potential risk of including raw data or irrelevant information. Additionally, the Plan should ensure that the context is properly set for each LLM generation step to maintain coherence and relevance throughout the answer generation process.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=a301ba2a-1639-456b-8c89-8d5942436ac4,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:28,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Not Pass! How to generate the DDL statements for all tables in TiDB?, the evaluation result:{\n",
      "  \"accept\": false,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer does not fully resolve the user's Goal. The answer provides example DDL statements for specific tables in the INFORMATION_SCHEMA, but it does not explain how to generate DDL statements for all user-defined tables in a TiDB database. The Plan should include steps to retrieve and process information on how to extract DDL statements for all tables in a TiDB database, not just the INFORMATION_SCHEMA tables. Additionally, the Plan should ensure that the answer includes a method or SQL query that can be executed to achieve the user's goal. The Plan should also implement dual retrieval using both retrieve_knowledge_graph and vector_search tools to ensure comprehensive information gathering.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Failed to evaluate plan for task(id=a301ba2a-1639-456b-8c89-8d5942436ac4): Still failed after two evaluations round.\n",
      "Start to evaluate plan for task(id=b0481b98-92c6-4fd1-944a-8a9d383d86a6,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:32,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! How to address the error related to assertion failure in TiDB, specifically the \"assertion failure\" in prewrite.rs, and what steps can be taken to resolve it?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively resolves the user's Goal by providing a comprehensive analysis of the prewrite phase in TiDB and offering actionable solutions to address the assertion failure. However, the Plan could be improved by ensuring dual retrieval is consistently applied. Specifically, after retrieving information from both the knowledge graph and vector search, the Plan should immediately process these combined results through the LLM generation tool to extract key insights and present a coherent narrative. This would enhance the efficiency and coherence of the answer generation process.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=b3b537af-ef4b-4fc9-a612-fcc448aa5f57,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:38,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! What is the ticdc_kvclient_cached_region metric in TiDB?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"While the answer is acceptable, the Plan could be improved by ensuring that the retrieval steps are more focused on the specific metric rather than general TiCDC metrics. Additionally, the Plan should ensure that the retrieval process includes a step to verify the relevance and accuracy of the retrieved information before synthesis. Implementing dual retrieval consistently and processing results immediately through the LLM generation tool could enhance the quality and relevance of the final answer.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=c255c42b-c85d-450f-aa2b-b101f37adef8,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:43,069 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Not Pass! Who are you?, the evaluation result:{\n",
      "  \"accept\": false,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer does not directly address the user's Goal of understanding the identity and capabilities of the TiDB Docs Bot. The Plan should include a step to explicitly state the identity and capabilities of the TiDB Docs Bot, as outlined in the supplementary goal information. This could involve directly incorporating the information from the prompt used in the 'llm_generate' tool into the Final Answer. Additionally, the Plan should ensure that the generated response clearly communicates the bot's role and functions to the user.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Failed to evaluate plan for task(id=c255c42b-c85d-450f-aa2b-b101f37adef8): Still failed after two evaluations round.\n",
      "Start to evaluate plan for task(id=c5c0bc70-8b3f-437e-9c4b-4563e4c79be4,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:47,538 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! When does disk space get reclaimed for row deletions in TiDB?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"While the answer is acceptable, the Plan could be improved by ensuring that the retrieval process explicitly checks for the most recent and relevant documentation to avoid potential outdated information. Additionally, the Plan could benefit from a step that verifies the accuracy of the retrieved information against the latest TiDB updates or release notes to ensure the answer remains current.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=cf211e26-2517-4264-8354-d2989f594093,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:52,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! What is the maximum number of nodes that a TiDB cluster can have in a real-world scenario?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The answer effectively resolves the user's goal by providing detailed information on the scalability limits of TiDB, TiKV, and PD nodes. However, the Plan could be improved by ensuring that the retrieval process includes a step to verify the most current and comprehensive data from both the knowledge graph and vector search. Additionally, the Plan should ensure that the retrieval tools are used in a complementary manner to cover any potential gaps in information. This could involve a more explicit integration of the results from both retrieval methods before generating the final answer.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=d86ef57b-946a-4d69-b3b1-d9e04beb0bd2,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:39:57,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! How to evaluate the impact of future expansion plans on the choice between TiDB and Citus? What specific measures do TiDB and Citus have for handling data security and privacy? How is Citus's sharding capability specifically implemented in multi-tenant application scenarios? What are some successful cases of TiDB's HTAP capabilities in practical applications? In scenarios involving geographically distributed data, how does Citus ensure data consistency and access speed?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively addresses the user's Goal by providing a comprehensive comparison of TiDB and Citus across various dimensions such as scalability, security, sharding, HTAP capabilities, and geographic distribution. However, the Plan could be improved by ensuring that each retrieval step is immediately followed by processing through the LLM generation tool to extract key insights and present a coherent narrative. Additionally, the Plan should ensure that all relevant aspects of the Goal are covered, such as providing more specific examples of successful HTAP implementations in TiDB and detailed security measures in Citus. This would enhance the depth and relevance of the Final Answer.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n",
      "Start to evaluate plan for task(id=efbdb0ed-835b-4584-b0ff-5b1cc075ef4b,branch=main)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:40:02,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Pass! Why do we need the PD (Placement Driver) microservice in TiDB, and in what scenarios or data volume should it be enabled?, evaluation result:{\n",
      "  \"accept\": true,\n",
      "  \"plan_adjustment_suggestion\": \"The Final Answer effectively addresses the user's Goal by explaining the role of the PD component in TiDB and the scenarios where it is essential. However, the Plan could be improved by ensuring that the retrieval steps are more focused on the specific aspects of the Goal, such as the data volume thresholds for enabling PD. Additionally, the Plan could benefit from a more streamlined approach by reducing the number of retrieval steps and ensuring that each retrieval directly contributes to the final answer. Implementing dual retrieval for each query and immediately processing the results through the LLM generation tool could enhance efficiency and coherence.\",\n",
      "  \"goal_classification\": \"Direct Problem Resolution\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for task in pending_tasks:\n",
    "    task_id = task[\"id\"]\n",
    "    optimize_plan(task_id, \"main\", max_iteration=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
