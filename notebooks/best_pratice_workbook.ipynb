{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add the project root to Python path\n",
    "from app.core.labels.classifier import LabelClassifier\n",
    "from app.llm.interface import LLMInterface\n",
    "from app.config.settings import REASON_LLM_PROVIDER, REASON_LLM_MODEL\n",
    "\n",
    "classifer = LabelClassifier(LLMInterface(REASON_LLM_PROVIDER, REASON_LLM_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer.label_tree.light_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 'b96fe4ab-555d-4b00-8a00-acd4ec660eab'\n",
    "task_goal = 'How to troubleshoot slow DDL execution when adding partitions in TiDB?'\n",
    "label_path = classifer.generate_label_description(\"Default\", task_goal)\n",
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = [\n",
    "    {\n",
    "        'label': 'Other Topics',\n",
    "        'description': \"General technical discussions and queries that don't fit into the other categories.\"\n",
    "    },{\n",
    "        'label': 'Tidb Unrelated',\n",
    "        'description': 'Questions that are not related to TiDB.'\n",
    "    }\n",
    "]\n",
    "\n",
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer.insert_label_path(\"Default\", task_id, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def save_best_plan_from_url(url):\n",
    "    \n",
    "    try:\n",
    "        # Split URL by '/' and extract components\n",
    "        parts = url.split('/')\n",
    "        \n",
    "        # Find index of 'tasks' and extract task_id and commit_hash\n",
    "        if 'tasks' in parts:\n",
    "            tasks_index = parts.index('tasks')\n",
    "            if len(parts) < tasks_index + 4:  # Ensure we have enough parts after 'tasks'\n",
    "                raise ValueError(\"Invalid URL format\")\n",
    "                \n",
    "            task_id = parts[tasks_index + 1]\n",
    "            commit_hash = parts[tasks_index + 3]\n",
    "\n",
    "            url = f\"https://stackvm.tidb.ai/api/tasks/{task_id}/commits/{commit_hash}/save_best_plan\"\n",
    "            response = requests.post(url)\n",
    "            if response.status_code != 200:\n",
    "                raise ValueError(\"Failed to save best plan\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "url = \"https://stackvm-ui.vercel.app/tasks/b95526f7-7539-432b-ab98-9b46bfb5c8ac/main/baff324f1f164a25b24856db4db7aa6b/final-answer\"\n",
    "save_best_plan_from_url(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    {\n",
    "        \"label\": \"Troubleshooting\",\n",
    "        \"description\": \"Diagnostic guidance and problem-solving approaches for system issues, error conditions, or unexpected behaviors.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "matching_node = classifer.label_tree.find_longest_matching_label(labels)\n",
    "tasks = classifer.label_tree.get_all_tasks_under_label(matching_node)\n",
    "tasks\n",
    "\n",
    "#tasks_plan = get_task_plans([task[\"id\"] for task in tasks])\n",
    "#tasks_plan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "\n",
    "def format_tasks_plans(\n",
    "    node: Dict[str, Any],\n",
    "    current_path: List[str] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Traverses the tree structure and formats each task into a specified text format.\n",
    "\n",
    "    Parameters:\n",
    "    - node (Dict[str, Any]): The current node in the tree.\n",
    "    - task_plans (Dict[str, Dict[str, Any]]): A dictionary mapping task IDs to their best plans.\n",
    "    - current_path (List[str], optional): The path of labels from the root to the current node.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted text containing all tasks.\n",
    "    \"\"\"\n",
    "    if current_path is None:\n",
    "        current_path = []\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Update the current path with the current node's name\n",
    "    node_name = node.get(\"name\", \"\")\n",
    "    new_path = current_path + [node_name] if node_name else current_path\n",
    "\n",
    "    # Process tasks in the current node\n",
    "    tasks = node.get(\"tasks\", [])\n",
    "    for task in tasks:\n",
    "        task_id = task.get(\"id\")\n",
    "        task_goal = task.get(\"goal\")\n",
    "        best_plan = task.get(\"best_plan\",  None)\n",
    "        if best_plan is None:\n",
    "            continue\n",
    "\n",
    "        task_text = (\n",
    "            f\"task: {task_goal}\\n\"\n",
    "            f\"label_path: {' -> '.join(new_path)}\\n\"\n",
    "            f\"best_plan: {best_plan}\\n\"\n",
    "            \"-------\\n\"\n",
    "        )\n",
    "        output.append(task_text)\n",
    "\n",
    "    # Recursively process child nodes\n",
    "    children = node.get(\"children\", [])\n",
    "    for child in children:\n",
    "        output.append(format_tasks_plans(child, new_path))\n",
    "\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.llm.interface import LLMInterface\n",
    "from app.config.settings import LLM_PROVIDER, LLM_MODEL\n",
    "from app.core.plan.prompts import get_best_pratices_prompt\n",
    "\n",
    "\n",
    "formatted_task_plan =  format_tasks_plans(matching_node)\n",
    "label_path = ' -> '.join([label[\"label\"] for label in labels])\n",
    "prompt = get_best_pratices_prompt(label_path, formatted_task_plan)\n",
    "\n",
    "best_pratices_str = LLMInterface(LLM_PROVIDER, LLM_MODEL).generate(prompt)\n",
    "print(best_pratices_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_practices_str = \"\"\"To solve tasks in the <Troubleshooting> category, please follow this approach:\n",
    "1. Problem Analysis and Hypothesis Generation\n",
    "  - Clearly define the scope and impact of the issue during the initial reasoning phase (Problem Framing).\n",
    "  - Generate multiple hypotheses or potential causes (Hypothesis Generation) to avoid narrowing the investigation too early.\n",
    "  - This step ensures a thorough understanding of the problem and provides a roadmap for subsequent research and analysis.\n",
    "\n",
    "  The example of chain_of_thoughts: \"The main issue stems from the concentrated write operations due to a date prefix index, resulting in an index hotspot. Optimizing the index by replacing the date prefix could help scatter writes more evenly, potentially using attributes like user ID for better distribution. Moreover, partitioning tables can be a robust method to further distribute writes across multiple regions, spreading out the load and addressing the hotspot problem effectively. This approach involves both adjusting the index structure and implementing partitioned tables as a combined strategy.\",\n",
    "\n",
    "\n",
    "2. Multi-Channel Information Gathering and Cross-Verification\n",
    "  - Leverage a Knowledge Graph for structured insights and connections related to the issue.\n",
    "  - Use Vector Search to locate similar cases or documentation based on content similarity.\n",
    "  - Ttailor your queries/prompts to address specific error points rather than general issues/topics. This ensures that both the data collected and the subsequent analysis are closely aligned with the problem at hand.\n",
    "  -\tEmploy LLM-based summarization and inference to synthesize findings from various sources.\n",
    "  - By integrating different sources of information, you gain a more comprehensive understanding of the root causes and possible solutions.\n",
    "\n",
    "3.\tReasoning and Solution Generation (With Irrelevant Solution Filtering)\n",
    "\n",
    "  - During the reasoning phase, evaluate the collected information against your initial hypotheses.\n",
    "  - Filter out any solutions or suggestions that do not directly address the identified problem to ensure relevancy.\n",
    "  - Consolidate valid insights into clear, actionable recommendations.\n",
    "  - This ensures that the final solutions are both targeted and feasible for resolving the specific issue at hand.\n",
    "\n",
    "By following these steps—starting with thorough problem analysis, then gathering and verifying data from multiple sources, and finally synthesizing a well-founded solution while filtering out irrelevant approaches—you can enhance the accuracy and efficiency of your troubleshooting efforts.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.storage.models import Label\n",
    "from app.config.database import SessionLocal\n",
    "\n",
    "with SessionLocal() as session:\n",
    "    label = session.query(Label).filter(Label.name == labels[-1].get(\"label\")).first()\n",
    "    label.best_practices = best_practices_str\n",
    "    session.add(label)\n",
    "    session.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
