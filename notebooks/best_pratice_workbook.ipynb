{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: spec.md file not found at /Users/ian/Work/stackvm/notebooks/spec.md\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add the project root to Python path\n",
    "from app.controller.label_classifier import LabelClassifier\n",
    "\n",
    "classifer = LabelClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer.label_tree.light_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Troubleshooting',\n",
       "  'description': 'Diagnostic guidance and problem-solving approaches for system issues, error conditions, or unexpected behaviors.'},\n",
       " {'label': 'SQL Optimization',\n",
       "  'description': 'Strategies, best practices, and techniques for enhancing the performance and efficiency of SQL queries.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id = 'f5d131fb-e531-4401-a22a-9f1f6f1c2e04'\n",
    "task_goal = 'The user is experiencing performance issues when executing a simple SELECT * FROM table_name LIMIT 1 query on a large table in TiDB. The execution plan indicates that the query takes over 20 seconds to complete, despite having sufficient memory and CPU resources. The table has been configured with TTL (Time to Live), which might be affecting performance. The user is using TiDB version 8.1 in a POC environment. 8000w的表不加order where条件limit 1要20多秒 【 TiDB 使用环境】Poc 【 TiDB 版本】V8.1 【复现路径】对应的表加过ttl 【遇到的问题：问题现象及影响】 sql select * from table_name limit 1 执行计划 | id | estRows | estCost | actRows | task | access object | execution info | operator info | memory | disk | | Limit_7 | 1.00 | 67.35 | 0 | root | | time:29.4s, loops:1 | offset:0, count:1 | N/A | N/A | | └─TableReader_11 | 1.00 | 67.35 | 0 | root | | time:29.4s, loops:1, cop_task: {num: 794, max: 472.2ms, min: 485.7µs, avg: 36.8ms, p95: 231.7ms, tot_proc: 28.5s, tot_wait: 251.7ms, copr_cache_hit_ratio: 0.78, build_task_duration: 705.1ms, max_distsql_concurrency: 1}, rpc_info:{Cop:{num_rpc:794, total_time:29.2s}} | data:Limit_10 | 339 Bytes | N/A | | └─Limit_10 | 1.00 | 305.49 | 0 | cop[tikv] | | tikv_task:{proc max:471ms, min:0s, avg: 114ms, p80:147ms, p95:260ms, iters:794, tasks:794}, scan_detail: {total_keys: 86977944, get_snapshot_time: 230.8ms, rocksdb: {delete_skipped_count: 6326304, key_skipped_count: 93304074, block: {cache_hit_count: 2379, read_count: 150700, read_byte: 1.03 GB, read_time: 4.27s}}}, time_detail: {total_process_time: 28.5s, total_wait_time: 251.7ms, total_kv_read_wall_time: 28.4s, tikv_wall_time: 28.9s} | offset:0, count:1 | N/A | N/A | | └─TableFullScan_9 | 1.00 | 305.49 | 0 | cop[tikv] | table:data_event_relation | tikv_task:{proc max:471ms, min:0s, avg: 114ms, p80:147ms, p95:260ms, iters:794, tasks:794} | keep order:false | N/A | N/A | 【资源配置】 内存cpu充足'\n",
    "label_path = classifer.generate_label_description(task_goal)\n",
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = [\n",
    "  {'label': 'Troubleshooting',\n",
    "  'description': 'Diagnostic guidance and problem-solving approaches for system issues, error conditions, or unexpected behaviors. Focuses on root cause analysis and resolution strategies for common operational challenges.'},\n",
    " {'label': 'SQL Optimization',\n",
    "   'description': 'Strategies, best practices, and techniques for enhancing the performance and efficiency of SQL queries. Focuses on query tuning, indexing, execution plan analysis, and reducing resource consumption in database systems to ensure scalability and responsiveness.'}\n",
    "]\n",
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer.insert_label_path(task_id, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def save_best_plan_from_url(url):\n",
    "    \n",
    "    try:\n",
    "        # Split URL by '/' and extract components\n",
    "        parts = url.split('/')\n",
    "        \n",
    "        # Find index of 'tasks' and extract task_id and commit_hash\n",
    "        if 'tasks' in parts:\n",
    "            tasks_index = parts.index('tasks')\n",
    "            if len(parts) < tasks_index + 4:  # Ensure we have enough parts after 'tasks'\n",
    "                raise ValueError(\"Invalid URL format\")\n",
    "                \n",
    "            task_id = parts[tasks_index + 1]\n",
    "            commit_hash = parts[tasks_index + 3]\n",
    "\n",
    "            url = f\"https://stackvm.tidb.ai/api/tasks/{task_id}/commits/{commit_hash}/save_best_plan\"\n",
    "            response = requests.post(url)\n",
    "            if response.status_code != 200:\n",
    "                raise ValueError(\"Failed to save best plan\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "url = \"https://stackvm-ui.vercel.app/tasks/f5d131fb-e531-4401-a22a-9f1f6f1c2e04/plan_update_20250110_052226/3ef8db3817434ec0b5843edfa67227a5/final-answer\"\n",
    "save_best_plan_from_url(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    {\n",
    "        \"label\": \"Troubleshooting\",\n",
    "        \"description\": \"Diagnostic guidance and problem-solving approaches for system issues, error conditions, or unexpected behaviors.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "matching_node = classifer.label_tree.find_longest_matching_label(labels)\n",
    "tasks = classifer.label_tree.get_all_tasks_under_label(matching_node)\n",
    "tasks\n",
    "\n",
    "#tasks_plan = get_task_plans([task[\"id\"] for task in tasks])\n",
    "#tasks_plan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "\n",
    "def format_tasks_plans(\n",
    "    node: Dict[str, Any],\n",
    "    current_path: List[str] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Traverses the tree structure and formats each task into a specified text format.\n",
    "\n",
    "    Parameters:\n",
    "    - node (Dict[str, Any]): The current node in the tree.\n",
    "    - task_plans (Dict[str, Dict[str, Any]]): A dictionary mapping task IDs to their best plans.\n",
    "    - current_path (List[str], optional): The path of labels from the root to the current node.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted text containing all tasks.\n",
    "    \"\"\"\n",
    "    if current_path is None:\n",
    "        current_path = []\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Update the current path with the current node's name\n",
    "    node_name = node.get(\"name\", \"\")\n",
    "    new_path = current_path + [node_name] if node_name else current_path\n",
    "\n",
    "    # Process tasks in the current node\n",
    "    tasks = node.get(\"tasks\", [])\n",
    "    for task in tasks:\n",
    "        task_id = task.get(\"id\")\n",
    "        task_goal = task.get(\"goal\")\n",
    "        best_plan = task.get(\"best_plan\",  None)\n",
    "        if best_plan is None:\n",
    "            continue\n",
    "\n",
    "        task_text = (\n",
    "            f\"task: {task_goal}\\n\"\n",
    "            f\"label_path: {' -> '.join(new_path)}\\n\"\n",
    "            f\"best_plan: {best_plan}\\n\"\n",
    "            \"-------\\n\"\n",
    "        )\n",
    "        output.append(task_text)\n",
    "\n",
    "    # Recursively process child nodes\n",
    "    children = node.get(\"children\", [])\n",
    "    for child in children:\n",
    "        output.append(format_tasks_plans(child, new_path))\n",
    "\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.llm_interface import LLMInterface\n",
    "from app.config.settings import LLM_PROVIDER, FAST_LLM_MODEL\n",
    "from app.services import get_best_pratices_prompt\n",
    "\n",
    "\n",
    "formatted_task_plan =  format_tasks_plans(matching_node)\n",
    "label_path = ' -> '.join([label[\"label\"] for label in labels])\n",
    "prompt = get_best_pratices_prompt(label_path, formatted_task_plan)\n",
    "\n",
    "best_pratices_str = LLMInterface(LLM_PROVIDER, FAST_LLM_MODEL).generate(prompt)\n",
    "print(best_pratices_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_practices_str = \"\"\"To solve tasks in the <Troubleshooting> category, please follow this approach:\n",
    "1. Problem Analysis and Hypothesis Generation\n",
    "  - Clearly define the scope and impact of the issue during the initial reasoning phase (Problem Framing).\n",
    "  - Generate multiple hypotheses or potential causes (Hypothesis Generation) to avoid narrowing the investigation too early.\n",
    "  - This step ensures a thorough understanding of the problem and provides a roadmap for subsequent research and analysis.\n",
    "\n",
    "  The example of chain_of_thoughts: \"The main issue stems from the concentrated write operations due to a date prefix index, resulting in an index hotspot. Optimizing the index by replacing the date prefix could help scatter writes more evenly, potentially using attributes like user ID for better distribution. Moreover, partitioning tables can be a robust method to further distribute writes across multiple regions, spreading out the load and addressing the hotspot problem effectively. This approach involves both adjusting the index structure and implementing partitioned tables as a combined strategy.\",\n",
    "\n",
    "\n",
    "2. Multi-Channel Information Gathering and Cross-Verification\n",
    "  - Leverage a Knowledge Graph for structured insights and connections related to the issue.\n",
    "  - Use Vector Search to locate similar cases or documentation based on content similarity.\n",
    "  - Ttailor your queries/prompts to address specific error points rather than general issues/topics. This ensures that both the data collected and the subsequent analysis are closely aligned with the problem at hand.\n",
    "  -\tEmploy LLM-based summarization and inference to synthesize findings from various sources.\n",
    "  - By integrating different sources of information, you gain a more comprehensive understanding of the root causes and possible solutions.\n",
    "\n",
    "3.\tReasoning and Solution Generation (With Irrelevant Solution Filtering)\n",
    "\n",
    "  - During the reasoning phase, evaluate the collected information against your initial hypotheses.\n",
    "  - Filter out any solutions or suggestions that do not directly address the identified problem to ensure relevancy.\n",
    "  - Consolidate valid insights into clear, actionable recommendations.\n",
    "  - This ensures that the final solutions are both targeted and feasible for resolving the specific issue at hand.\n",
    "\n",
    "By following these steps—starting with thorough problem analysis, then gathering and verifying data from multiple sources, and finally synthesizing a well-founded solution while filtering out irrelevant approaches—you can enhance the accuracy and efficiency of your troubleshooting efforts.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models.label import Label\n",
    "from app.database import SessionLocal\n",
    "\n",
    "with SessionLocal() as session:\n",
    "    label = session.query(Label).filter(Label.name == labels[-1].get(\"label\")).first()\n",
    "    label.best_practices = best_practices_str\n",
    "    session.add(label)\n",
    "    session.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
