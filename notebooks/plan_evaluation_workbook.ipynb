{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: spec.md file not found at /Users/ianz/Work/stackvm/notebooks/spec.md\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add the project root to Python path\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "from app.services.llm_interface import LLMInterface\n",
    "from app.config.settings import LLM_MODEL, LLM_PROVIDER\n",
    "\n",
    "stackvm_host = os.getenv(\"STACKVM_HOST\", None)\n",
    "assert stackvm_host is not None, \"STACKVM_HOST environment variable is not set.\"\n",
    "\n",
    "def get_task_branch_answer_detail(task_id: str, branch_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the answer detail for a specific task and branch using the API.\n",
    "\n",
    "    Args:\n",
    "        task_id: The ID of the task.\n",
    "        branch_name: The name of the branch.\n",
    "        base_url: The base URL of the API.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the API response, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    url = f\"{stackvm_host}/api/tasks/{task_id}/branches/{branch_name}/answer_detail\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        raise e\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON response: {e}\")\n",
    "        raise e\n",
    "\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "def update_task_from_scratch(\n",
    "    task_id: str,\n",
    "    suggestion: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Updates a task with a new suggestion and sets the task to be re-run from scratch.\n",
    "    \"\"\"\n",
    "    url = f\"{stackvm_host}/api/tasks/{task_id}/update\"\n",
    "    \n",
    "    payload = {\n",
    "        \"suggestion\": suggestion,\n",
    "        \"from_scratch\": True\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if response.status_code == 400:\n",
    "            raise ValueError(\"Missing required parameters: suggestion\")\n",
    "        elif response.status_code == 404:\n",
    "            raise ValueError(f\"Task with ID {task_id} not found\")\n",
    "        elif response.status_code == 500:\n",
    "            raise ValueError(\"Failed to update plan\")\n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "\n",
    "llm_client = LLMInterface(LLM_PROVIDER, LLM_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_task(goal, answer, plan):\n",
    "    evluation_prompt = f\"\"\"You are tasked with evaluating and improving the effectiveness of a problem-solving workflow. Below is a description of a Goal, a Plan used to address it, and the Final Answer generated. Your task is to evaluate the quality of the answer and diagnose whether the plan sufficiently aligned with the goal. If issues are present (e.g., the answer does not fully meet the goal or contains irrelevant information), you must:\n",
    "1. Analyze the Plan to identify weaknesses or misalignments with the Goal.\n",
    "2. Provide detailed suggestions to adjust or rewrite the Plan to improve the answer quality.\n",
    "\n",
    "Your output must include:\n",
    "1. Answer Quality Assessment: Clearly state whether the final answer resolves the goal. If not, explain why and identify any irrelevant or missing elements.\n",
    "2. Plan Analysis: Examine the steps in the plan, identify where they failed or could be improved, and explain why adjustments are necessary.\n",
    "3. Plan Adjustment Suggestions: Provide a revised or improved version of the plan to address the identified shortcomings.\n",
    "\n",
    "Here are the inputs:\n",
    "\n",
    "## Goal \n",
    "{goal}\n",
    "\n",
    "## Answer\n",
    "{answer}\n",
    "\n",
    "## plan\n",
    "{plan}\n",
    "\n",
    "Your Output Format:\n",
    "You must return a JSON object with the following keys:\n",
    "- accept: Boolean value (true or false) indicating whether the final answer effectively resolves the goal.\n",
    "- answer_quality_assessment_explaination: A detailed explanation justifying why the final answer does or does not meet the goal, highlighting key points or missing elements.\n",
    "- plan_adjustment_suggestion: If answer is not accepted, please provide a comprehensive analysis of the plan and recommendations for how to adjust or improve it to better achieve the goal.\n",
    "\n",
    "Example Output:\n",
    "{{\n",
    "  \"accept\": False/True,\n",
    "  \"answer_quality_assessment_explaination\": \"...\",\n",
    "  \"plan_adjustment_suggestion\": {...}\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    return llm_client.generate(prompt=evluation_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to evaluate plan for task(id=5575fe37-6b39-493a-929a-42112416a86f,branch=main)\n",
      "Update plan based on the suggestion: {'Plan Analysis': 'The plan has several weaknesses. First, it does not clearly separate the configuration of `region-split-size` from other unrelated configuration changes. The plan also includes unnecessary steps that do not contribute to achieving the goal, such as modifying unrelated system variables. Additionally, the plan does not ensure that the generated answer is concise and focused on the specific goal.', 'Plan Adjustment Suggestions': [{'Step 1': 'Refine the initial reasoning to focus exclusively on the `region-split-size` configuration and persistence. Remove any mention of unrelated system variables.', 'Step 2': 'Ensure that the vector search and knowledge graph retrieval steps are specifically targeted at `region-split-size` persistence, avoiding general configuration topics.', 'Step 3': 'Generate configuration steps that are clear and concise, focusing solely on modifying the `tidb.toml` file and verifying the changes.', 'Step 4': 'Remove any steps related to modifying or verifying unrelated system variables.', 'Step 5': 'Ensure the final answer is structured to clearly separate configuration and verification steps, with a focus on the `region-split-size`.'}]}\n",
      "{'current_branch': 'plan_update_20250102_133637', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from app.utils.json import extract_json\n",
    "\n",
    "task_id = '5575fe37-6b39-493a-929a-42112416a86f'\n",
    "# task_id = 'c3382869-e2b2-4244-b971-d00a14701681'\n",
    "# task_id = 'fe605c06-1fc5-47d8-a728-25f1a025befd'\n",
    "branch_name = 'main'\n",
    "\n",
    "print(f\"Start to evaluate plan for task(id={task_id},branch={branch_name})\")\n",
    "\n",
    "detail = get_task_branch_answer_detail(task_id, branch_name)\n",
    "\n",
    "state = detail.get('vm_state')\n",
    "goal_completed = False\n",
    "final_answer = None\n",
    "plan = None\n",
    "goal = None\n",
    "\n",
    "if state is not None:\n",
    "    plan = state.get(\"current_plan\", None)\n",
    "    goal_completed = state.get(\"goal_completed\", False)\n",
    "    goal = state.get(\"goal\", None)\n",
    "    if state.get(\"variables\", None) is not None:\n",
    "        final_answer = state['variables'].get(\"final_answer\", None)\n",
    "\n",
    "    if goal is not None and goal_completed is True and plan is not None and final_answer is not None:\n",
    "        response = evaluation_task(goal, final_answer, plan)\n",
    "        eval_res_str = extract_json(response)\n",
    "        eval_res = json.loads(eval_res_str)\n",
    "        accept = eval_res.get(\"accept\", None)\n",
    "\n",
    "        if accept is not True:\n",
    "            explanation = eval_res.get(\"answer_quality_assessment_explaination\", None)\n",
    "            suggestion = eval_res.get(\"plan_adjustment_suggestion\", None)\n",
    "\n",
    "            if suggestion is not None:\n",
    "                print(f\"Update plan based on the suggestion: {suggestion}\")\n",
    "                print(f\"Explanation: {explanation}\")\n",
    "                #suggestion_str = json.dumps(suggestion)\n",
    "                #update_response = update_task_from_scratch(task_id, suggestion_str)\n",
    "                #print(update_response)\n",
    "            else:\n",
    "                print(\"No suggestion found\")\n",
    "        else:\n",
    "            print(\"The final answer is accepted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
