{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: spec.md file not found at /Users/ian/Work/stackvm/notebooks/spec.md\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add the project root to Python path\n",
    "\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from notebooks.plan_chat_optimizer import get_task_answer, update_plan, execute_task_using_new_plan, stackvm_host\n",
    "from app.core.plan.evaluator import evaulate_answer\n",
    "\n",
    "def get_evaluation_pending_tasks(        \n",
    "    start_time: Optional[datetime] = None,\n",
    "    end_time: Optional[datetime] = None,\n",
    "    evaluation_statuses: Optional[List[str]] = None\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetches the list of tasks pending evaluation from the API.\n",
    "\n",
    "    Args:\n",
    "        start_time (Optional[datetime]): The start time to filter tasks.\n",
    "        end_time (Optional[datetime]): The end time to filter tasks.\n",
    "        evaluation_statuses (Optional[List[str]]): List of evaluation statuses to filter by. Defaults to ['NOT_EVALUATED'].\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of tasks pending evaluation.\n",
    "    \n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If the request fails.\n",
    "        ValueError: If the response cannot be decoded.\n",
    "    \"\"\"\n",
    "    endpoint = f\"{stackvm_host}/api/tasks/evaluation\"\n",
    "    params = {}\n",
    "    \n",
    "    if start_time:\n",
    "        params['start_time'] = start_time.isoformat()\n",
    "    if end_time:\n",
    "        params['end_time'] = end_time.isoformat()\n",
    "    if evaluation_statuses:\n",
    "        # Join multiple statuses with commas\n",
    "        params['evaluation_status'] = ','.join(evaluation_statuses)\n",
    "    else:\n",
    "        # Default to NOT_EVALUATED if no statuses are provided\n",
    "        params['evaluation_status'] = 'NOT_EVALUATED'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4XX or 5XX)\n",
    "        data = response.json()\n",
    "        \n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(\"Unexpected response format: Expected a list of tasks.\")\n",
    "        \n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle network-related errors\n",
    "        print(f\"An error occurred while making the request: {e}\")\n",
    "        raise\n",
    "    except ValueError as ve:\n",
    "        # Handle JSON decoding errors or unexpected data formats\n",
    "        print(f\"An error occurred while processing the response: {ve}\")\n",
    "        raise\n",
    "\n",
    "def record_evaluation(\n",
    "    task_id: str,\n",
    "    evaluation_status: str,\n",
    "    evaluation_reason: Optional[str] = \"\",\n",
    "    timeout: int = 60\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Records the evaluation result of a specific task by calling the API endpoint.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API (e.g., 'http://stackvm-dev.tidb.ai:5556').\n",
    "        task_id (str): The ID of the task to be evaluated.\n",
    "        evaluation_status (str): The evaluation status (e.g., \"APPROVED\", \"REJECTED\").\n",
    "        evaluation_reason (Optional[str]): The reason for the evaluation decision.\n",
    "        api_token (Optional[str]): API token for authentication, if required.\n",
    "        timeout (int): Timeout in seconds for the API request.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The JSON response from the API indicating success or failure.\n",
    "    \n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If the request fails.\n",
    "        ValueError: If the response cannot be decoded or contains an error.\n",
    "    \"\"\"\n",
    "    endpoint = f\"{stackvm_host}/api/tasks/{task_id}/evaluation\"\n",
    "    payload = {\n",
    "        \"evaluation_status\": evaluation_status,\n",
    "        \"evaluation_reason\": evaluation_reason\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(endpoint, json=payload, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Unexpected response format: Expected a JSON object.\")\n",
    "\n",
    "        if not data.get(\"success\", False):\n",
    "            error_message = data.get(\"error\", \"Unknown error occurred.\")\n",
    "            raise ValueError(f\"API Error: {error_message}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while making the request: {e}\")\n",
    "        raise\n",
    "    except ValueError as ve:\n",
    "        print(f\"An error occurred while processing the response: {ve}\")\n",
    "        raise\n",
    "\n",
    "def record_human_evaluation(\n",
    "    task_id: str,\n",
    "    evaluation_status: str,\n",
    "    feedback: Optional[str] = \"\",\n",
    "    timeout: int = 60\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Records the evaluation result of a specific task by calling the API endpoint.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the API (e.g., 'http://stackvm-dev.tidb.ai:5556').\n",
    "        task_id (str): The ID of the task to be evaluated.\n",
    "        evaluation_status (str): The evaluation status (e.g., \"APPROVED\", \"REJECTED\").\n",
    "        evaluation_reason (Optional[str]): The reason for the evaluation decision.\n",
    "        api_token (Optional[str]): API token for authentication, if required.\n",
    "        timeout (int): Timeout in seconds for the API request.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The JSON response from the API indicating success or failure.\n",
    "    \n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If the request fails.\n",
    "        ValueError: If the response cannot be decoded or contains an error.\n",
    "    \"\"\"\n",
    "    endpoint = f\"{stackvm_host}/api/tasks/{task_id}/human_evaluation\"\n",
    "    payload = {\n",
    "        \"evaluation_status\": evaluation_status,\n",
    "        \"feedback\": feedback\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(endpoint, json=payload, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Unexpected response format: Expected a JSON object.\")\n",
    "\n",
    "        if not data.get(\"success\", False):\n",
    "            error_message = data.get(\"error\", \"Unknown error occurred.\")\n",
    "            raise ValueError(f\"API Error: {error_message}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while making the request: {e}\")\n",
    "        raise\n",
    "    except ValueError as ve:\n",
    "        print(f\"An error occurred while processing the response: {ve}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from app.utils.json import extract_json\n",
    "from app.llm.interface import LLMInterface\n",
    "from app.config.settings import REASON_LLM_PROVIDER, REASON_LLM_MODEL\n",
    "\n",
    "eval_llm = LLMInterface(REASON_LLM_PROVIDER, REASON_LLM_MODEL)\n",
    "\n",
    "def optimize_plan(task_id:str, branch_name:Optional[str]=\"main\", max_iteration=2):\n",
    "    current_branch_name = branch_name\n",
    "    error_message = None\n",
    "    iteration_round = 0\n",
    "\n",
    "    while True:\n",
    "        print(f\"Start to evaluate plan for task(id={task_id},branch={current_branch_name})\")\n",
    "        detail = get_task_answer(task_id, current_branch_name)\n",
    "\n",
    "        if detail is not None:\n",
    "            goal = detail.get(\"goal\")\n",
    "            final_answer = detail.get(\"final_answer\")\n",
    "            plan = detail.get(\"plan\")\n",
    "            metadata = detail.get(\"metadata\")\n",
    "\n",
    "            eval_res = evaulate_answer(eval_llm, goal, metadata, final_answer, plan)\n",
    "            eval_status = \"APPROVED\" if eval_res.get(\"accept\", False) else \"REJECTED\"\n",
    "            eval_reason = json.dumps(eval_res, indent=2) \n",
    "\n",
    "            record_evaluation(task_id, eval_status, eval_reason)\n",
    "\n",
    "            if eval_res.get(\"accept\", False) is True:\n",
    "                print(f\"Goal Pass! {goal}, evaluation result:{eval_reason}\")\n",
    "                return\n",
    "\n",
    "            print(f\"Goal Not Pass! {goal}, the evaluation result:{eval_reason}\")\n",
    "\n",
    "            if iteration_round >= max_iteration:\n",
    "                break\n",
    "\n",
    "            revised_plan = update_plan(goal, metadata, plan, eval_reason)\n",
    "            reasoning = revised_plan.get(\"reasoning\", None)\n",
    "            revised_plan = revised_plan.get(\"plan\", None)\n",
    "            print(\"revised plan:\", reasoning, revised_plan)\n",
    "\n",
    "            try:\n",
    "                updated_result = execute_task_using_new_plan(task_id, revised_plan)\n",
    "                print(f\"Revised plan execution result {updated_result}\")\n",
    "            except Exception as e:\n",
    "                error_message = f\"Failed to execute task using new plan {e}\"\n",
    "                break\n",
    "            \n",
    "            current_branch_name = updated_result.get(\"branch_name\", None)\n",
    "            current_final_answer = updated_result.get(\"final_answer\", None)\n",
    "            if current_branch_name is None or current_final_answer is None:\n",
    "                error_message = \"Failed to execut task using new plan, get empty answer\"\n",
    "                break\n",
    "\n",
    "            iteration_round += 1\n",
    "    \n",
    "    if error_message is None:\n",
    "        error_message = \"Still failed after two evaluations round.\"\n",
    "    print(f\"Failed to evaluate plan for task(id={task_id}): {error_message}\")\n",
    "    record_human_evaluation(task_id, \"WAITTING_FOR_EVALUATION\", error_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.core.labels.classifier import LabelClassifier\n",
    "\n",
    "# optimize_plan(\"d89cab55-9930-41bb-b3ee-2de93d99246b\", \"main\")\n",
    "\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "pending_tasks = get_evaluation_pending_tasks(\n",
    "    start_time=start_time\n",
    ")\n",
    "\n",
    "for task in pending_tasks:\n",
    "    task_id = task[\"id\"]\n",
    "    optimize_plan(task_id, \"main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
